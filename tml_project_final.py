# -*- coding: utf-8 -*-
"""TML Project final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zAEe3an0e61RUaRbplwwQ12X-EA0a021
"""

!pip install lime

!pip install fairlearn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
import shap
import lime
from lime.lime_tabular import LimeTabularExplainer
from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="xgboost")

data = pd.read_csv("compas-scores-two-years.csv")

pd.set_option('display.width', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 5)

features = ['name', 'age', 'age_cat', 'sex', 'race', 'priors_count', 'c_charge_degree', 'decile_score']
target = 'two_year_recid'

X = data[features]
y = data[target]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(X_test.head(5).to_string(index=False))

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['age', 'priors_count', 'decile_score']),
        ('cat', OneHotEncoder(), ['age_cat', 'sex', 'race', 'c_charge_degree'])
    ])

X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

model = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    random_state=42
)

model.fit(X_train, y_train)


y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

num_features = preprocessor.transformers_[0][2]
cat_features = preprocessor.transformers_[1][1].get_feature_names_out(preprocessor.transformers_[1][2])

feature_names_transformed = np.concatenate([num_features, cat_features])

explainer = LimeTabularExplainer(
    X_train,
    training_labels=y_train,
    mode="classification",
    feature_names=feature_names_transformed,
    class_names=["Not Reoffend", "Reoffend"],
    discretize_continuous=True
)

i = 20
exp = explainer.explain_instance(X_test[i], model.predict_proba)

exp.show_in_notebook()

i = 20
exp = explainer.explain_instance(X_test[i], model.predict_proba)

print(f"Top features for instance {i}:")
for feature, weight in zip(exp.as_list(), exp.local_exp):
    print(f"{feature[0]}: {weight:.4f}")

shap_explainer = shap.TreeExplainer(model)

shap_values = shap_explainer.shap_values(X_test)

num_features = preprocessor.transformers_[0][2]
cat_features = preprocessor.transformers_[1][1].get_feature_names_out(preprocessor.transformers_[1][2])

feature_names_transformed = np.concatenate([num_features, cat_features])

shap.summary_plot(shap_values, X_test, feature_names=feature_names_transformed)

sex_indices = [i for i, name in enumerate(feature_names_transformed) if name.startswith('sex_')]
race_indices = [i for i, name in enumerate(feature_names_transformed) if name.startswith('race_')]

sex_shap_values = np.sum(shap_values[:, sex_indices], axis=1)
race_shap_values = np.sum(shap_values[:, race_indices], axis=1)

age_index = feature_names_transformed.tolist().index('age')
age_shap_values = shap_values[:, age_index]

plt.figure(figsize=(10, 6))
plt.boxplot([sex_shap_values, race_shap_values, age_shap_values],
            labels=['Sex', 'Race', 'Age'])
plt.title("SHAP Values for 'Sex', 'Race', and 'Age'")
plt.ylabel("SHAP Value")
plt.show()

sex_indices = [i for i, name in enumerate(feature_names_transformed) if name.startswith('sex_')]
race_indices = [i for i, name in enumerate(feature_names_transformed) if name.startswith('race_')]

sex_shap_values = np.sum(shap_values[:, sex_indices], axis=1)
race_shap_values = np.sum(shap_values[:, race_indices], axis=1)

avg_sex_shap = np.mean(np.abs(sex_shap_values))
avg_race_shap = np.mean(np.abs(race_shap_values))

print(f"Average SHAP value for 'sex': {avg_sex_shap}")
print(f"Average SHAP value for 'race': {avg_race_shap}")

sex_male_index = feature_names_transformed.tolist().index('sex_Male')
sex_female_index = feature_names_transformed.tolist().index('sex_Female')

group_1_sex = X_test[X_test[:, sex_male_index] == 1]
group_2_sex = X_test[X_test[:, sex_female_index] == 1]

shap_group_1 = shap_explainer.shap_values(group_1_sex)
shap_group_2 = shap_explainer.shap_values(group_2_sex)

avg_shap_group_1 = np.mean(np.abs(shap_group_1[:, sex_indices]), axis=0)
avg_shap_group_2 = np.mean(np.abs(shap_group_2[:, sex_indices]), axis=0)

print(f"Average SHAP values for 'sex' (Male): {avg_shap_group_1}")
print(f"Average SHAP values for 'sex' (Female): {avg_shap_group_2}")

male_indices = data.loc[y_test.index, 'sex'] == 'Male'
female_indices = data.loc[y_test.index, 'sex'] == 'Female'

y_pred_probs = model.predict_proba(X_test)[:, 1]
y_pred_binary = (y_pred_probs >= 0.5).astype(int)

dp_male = np.mean(y_pred_binary[male_indices])
dp_female = np.mean(y_pred_binary[female_indices])

print(f"Demographic Parity - Male Positive Rate: {dp_male:.3f}")
print(f"Demographic Parity - Female Positive Rate: {dp_female:.3f}")
print(f"Demographic Parity Difference: {abs(dp_male - dp_female):.3f}")

y_test_male = y_test[male_indices]
y_test_female = y_test[female_indices]

tpr_male = np.mean(y_pred_binary[male_indices][y_test_male == 1])
tpr_female = np.mean(y_pred_binary[female_indices][y_test_female == 1])

print(f"Equal Opportunity - Male TPR: {tpr_male:.3f}")
print(f"Equal Opportunity - Female TPR: {tpr_female:.3f}")
print(f"Equal Opportunity Difference: {abs(tpr_male - tpr_female):.3f}")

plt.boxplot([sex_shap_values[male_indices], sex_shap_values[female_indices]], labels=["Male", "Female"])
plt.title("Distribution of SHAP Values for 'Sex'")
plt.ylabel("SHAP Value")
plt.show()

constraint = DemographicParity()

fair_model = ExponentiatedGradient(estimator=model, constraints=constraint)

X_train_raw = data.loc[y_train.index]

fair_model.fit(X_train, y_train, sensitive_features=X_train_raw['sex'])

X_test_raw = data.loc[y_test.index]

y_pred_fair = fair_model.predict(X_test)

def demographic_parity_difference(y_true, y_pred, sensitive_features):
    """Calculates the difference in positive prediction rates between groups."""
    group_a = sensitive_features == sensitive_features.unique()[0]
    group_b = sensitive_features == sensitive_features.unique()[1]

    dp_a = np.mean(y_pred[group_a])
    dp_b = np.mean(y_pred[group_b])

    return abs(dp_a - dp_b)

def equalized_odds_difference(y_true, y_pred, sensitive_features):
    """Calculates the difference in TPR between groups."""
    group_a = sensitive_features == sensitive_features.unique()[0]
    group_b = sensitive_features == sensitive_features.unique()[1]

    tpr_a = np.mean(y_pred[group_a][y_true[group_a] == 1])
    tpr_b = np.mean(y_pred[group_b][y_true[group_b] == 1])

    return abs(tpr_a - tpr_b)

dp_diff_fair = demographic_parity_difference(y_test, y_pred_fair, sensitive_features=X_test_raw['sex'])
eo_diff_fair = equalized_odds_difference(y_test, y_pred_fair, sensitive_features=X_test_raw['sex'])

print(f"Fairlearn - Demographic Parity Difference: {dp_diff_fair:.3f}")
print(f"Fairlearn - Equal Opportunity Difference: {eo_diff_fair:.3f}")

dp_diff_before = abs(dp_male - dp_female)
eo_diff_before = abs(tpr_male - tpr_female)

dp_diff_after = abs(dp_diff_fair)
eo_diff_after = abs(eo_diff_fair)

fairness_comparison = pd.DataFrame({
    "Metric": ["Demographic Parity Difference", "Equal Opportunity Difference"],
    "Before": [dp_diff_before, eo_diff_before],
    "After": [dp_diff_after, eo_diff_after]
})

print(fairness_comparison)